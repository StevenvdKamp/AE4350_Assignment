{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cc3e212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\StevenvdKamp\\.conda\\envs\\VizDoom\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import vizdoom\n",
    "import numpy as np\n",
    "import cv2\n",
    "import stable_baselines3 as sb3\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "import sb3_contrib\n",
    "\n",
    "import optuna\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab203686",
   "metadata": {},
   "source": [
    "SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e178abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SCENARIO_PATH = r\"vizdoom\\scenarios\\defend_the_center_custom.cfg\"\n",
    "\n",
    "# Height and width of the resized image\n",
    "# IMAGE_SHAPE = (60, 80)\n",
    "\n",
    "# Training parameters\n",
    "TRAINING_TIMESTEPS = int(25e3)\n",
    "N_STEPS = 128\n",
    "N_ENVS = 1\n",
    "FRAME_SKIP = 4\n",
    "\n",
    "CHECKPOINT_DIR = './train/train_center'\n",
    "LOG_DIR = './logs/log_center'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f84f5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizDoomEnv(gym.Env):\n",
    "    def __init__(self, config_path, render=False):\n",
    "        super().__init__()\n",
    "\n",
    "        # Setup the Doom game environment\n",
    "        self.game = vizdoom.DoomGame()\n",
    "        self.game.load_config(config_path)\n",
    "        self.num_actions = 3  # Number of actions in the game (depends on scenario)\n",
    "\n",
    "        if render:\n",
    "            self.game.set_window_visible(True)\n",
    "        else:\n",
    "            self.game.set_window_visible(False)\n",
    "        \n",
    "        self.game.init()\n",
    "\n",
    "        # Create action space and observation space\n",
    "        self.action_space = gym.spaces.Discrete(self.num_actions)\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            shape=(100, 160, 1),\n",
    "            dtype=np.uint8\n",
    "        )\n",
    "\n",
    "        # Initialize previous values for shaping reward \n",
    "        self.ammo2_available_per_episode = self.game.get_state().game_variables[0]\n",
    "        self.previous_ammo2 = self.ammo2_available_per_episode\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        actions = np.eye(self.num_actions, dtype=np.uint8)\n",
    "        game_reward = self.game.make_action(actions[action], FRAME_SKIP)  # FRAME_SKIP ticks per action\n",
    "        terminated = self.game.is_episode_finished()\n",
    "\n",
    "        state = self.game.get_state()\n",
    "        if state is not None:\n",
    "            observation = self.simplify_observation(state.screen_buffer)\n",
    "            ammo2, health = state.game_variables\n",
    "\n",
    "            # Calculate deltas for shaping reward\n",
    "            delta_ammo2 = ammo2 - self.previous_ammo2\n",
    "\n",
    "            # Update previous values\n",
    "            self.previous_ammo2 = ammo2\n",
    "\n",
    "            # Calculate the shaped reward\n",
    "            shaped_reward = (\n",
    "                1 * game_reward\n",
    "                + 0.5 * delta_ammo2\n",
    "            )\n",
    "\n",
    "            # print(shaped_reward)\n",
    "\n",
    "            # print(f\"Shaped_reward: {shaped_reward}, Killcount: {killcount}, Hits Taken: {hits_taken}, Selected Weapon Ammo: {selected_weapon_ammo}\")\n",
    "\n",
    "            info = {\"info\": 0}\n",
    "        else:\n",
    "            observation = np.zeros(self.observation_space.shape, dtype=np.uint8)\n",
    "            shaped_reward = 0\n",
    "            info = {\"info\": 0}\n",
    "\n",
    "        return observation, shaped_reward, terminated, False, info\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        self.game.new_episode()\n",
    "        state = self.game.get_state()\n",
    "        observation = self.simplify_observation(state.screen_buffer)\n",
    "        # health, killcount, hits_taken, selected_weapon_ammo = state.game_variables\n",
    "        info = {\"info\": 0}\n",
    "\n",
    "        self.selected_weapon_ammo = self.ammo2_available_per_episode\n",
    "\n",
    "        return observation, info\n",
    "    \n",
    "    def close(self):\n",
    "        self.game.close()\n",
    "\n",
    "    def simplify_observation(self, observation):\n",
    "        # # Convert the observation to grayscale and resize it\n",
    "        gray_observation = cv2.cvtColor(np.moveaxis(observation,0,-1), cv2.COLOR_BGR2GRAY)\n",
    "        cropped_obervation = gray_observation[:100, :]\n",
    "        resized_observation = cv2.resize(cropped_obervation, None, fx=1, fy=1, interpolation=cv2.INTER_AREA)\n",
    "        simplified_observation = np.expand_dims(resized_observation, axis=-1)  # Add channel dimension\n",
    "        \n",
    "        # COLOR\n",
    "        # cropped_obervation = np.moveaxis(observation,0,-1)[:100, :, :]\n",
    "        # simplified_observation = cropped_obervation\n",
    "\n",
    "        return simplified_observation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d5f75a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# %matplotlib inline\n",
    "env = VizDoomEnv(DEFAULT_SCENARIO_PATH, render=True)\n",
    "observation = env.reset()[0]\n",
    "plt.imshow(cv2.cvtColor(observation, cv2.COLOR_BGR2RGB))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f185841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common import env_checker\n",
    "# Check validity of the environment\n",
    "env = VizDoomEnv(DEFAULT_SCENARIO_PATH)\n",
    "sb3.common.env_checker.check_env(env)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1833c8",
   "metadata": {},
   "source": [
    "Callback (saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "613b1a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_name = 'RPPO_blogAtariSettings_BW_V3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff10428",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(sb3.common.callbacks.BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, log_name=\"unkown\", verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "        self.log_name = log_name\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, '{}_best_model_{}'.format(self.log_name, self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True\n",
    "    \n",
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR, log_name=log_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9353108",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92d7c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non rendered environment\n",
    "envs = sb3.common.env_util.make_vec_env(VizDoomEnv, n_envs=N_ENVS, env_kwargs = {'config_path': DEFAULT_SCENARIO_PATH})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31e1085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# New fance pancy agent?\n",
    "agent = sb3_contrib.RecurrentPPO('CnnLstmPolicy', envs, verbose=1, tensorboard_log=LOG_DIR, n_steps=128, batch_size=4, gae_lambda=0.95, gamma=0.99, n_epochs=4, ent_coef=0.01, learning_rate=lambda f : f * 2.5e-4, clip_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c69a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload model from disc\n",
    "agent = sb3_contrib.RecurrentPPO.load(r'.\\train\\train_center\\RPPO_blogAtariSettings_BW.zip', env=envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c10369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "# model = PPO(\"CnnPolicy\", env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=1e-5, n_steps=2048)\n",
    "# model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=1e-4, n_steps=2048*4)\n",
    "# agent = sb3.PPO(\"CnnPolicy\", envs, verbose=1, tensorboard_log=LOG_DIR, learning_rate=1e-3, n_steps=N_STEPS)\n",
    "# model.learning_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a847825e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_center\\RPPO_blogAtariSettings_BW_V3_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 66       |\n",
      "|    ep_rew_mean     | -5       |\n",
      "| time/              |          |\n",
      "|    fps             | 82       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 128      |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 71           |\n",
      "|    ep_rew_mean          | -1.83        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 35           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 256          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025097402 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | -0.00485     |\n",
      "|    learning_rate        | 0.000249     |\n",
      "|    loss                 | 0.188        |\n",
      "|    n_updates            | 4            |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    value_loss           | 0.655        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 74.4         |\n",
      "|    ep_rew_mean          | -0.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 31           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 384          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052766814 |\n",
      "|    clip_fraction        | 0.162        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.0113       |\n",
      "|    learning_rate        | 0.000247     |\n",
      "|    loss                 | 0.554        |\n",
      "|    n_updates            | 8            |\n",
      "|    policy_gradient_loss | -0.00771     |\n",
      "|    value_loss           | 0.908        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 71.4         |\n",
      "|    ep_rew_mean          | -0.0714      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 29           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 512          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030419757 |\n",
      "|    clip_fraction        | 0.184        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.0864       |\n",
      "|    learning_rate        | 0.000246     |\n",
      "|    loss                 | 1.92         |\n",
      "|    n_updates            | 12           |\n",
      "|    policy_gradient_loss | -0.00964     |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 72.5         |\n",
      "|    ep_rew_mean          | 0.0625       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 640          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045067878 |\n",
      "|    clip_fraction        | 0.211        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.000245     |\n",
      "|    loss                 | 0.145        |\n",
      "|    n_updates            | 16           |\n",
      "|    policy_gradient_loss | -0.00923     |\n",
      "|    value_loss           | 0.68         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 75.6         |\n",
      "|    ep_rew_mean          | 0.2          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 768          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032922034 |\n",
      "|    clip_fraction        | 0.188        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.262        |\n",
      "|    learning_rate        | 0.000244     |\n",
      "|    loss                 | 0.0774       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | 0.000483     |\n",
      "|    value_loss           | 1.65         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.7         |\n",
      "|    ep_rew_mean          | 0.364        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 896          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046109054 |\n",
      "|    clip_fraction        | 0.35         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.0729       |\n",
      "|    learning_rate        | 0.000242     |\n",
      "|    loss                 | 0.663        |\n",
      "|    n_updates            | 24           |\n",
      "|    policy_gradient_loss | -0.0092      |\n",
      "|    value_loss           | 1.27         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.6        |\n",
      "|    ep_rew_mean          | 0.615       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 1024        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005371702 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.00902     |\n",
      "|    learning_rate        | 0.000241    |\n",
      "|    loss                 | 0.000728    |\n",
      "|    n_updates            | 28          |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    value_loss           | 0.834       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.7         |\n",
      "|    ep_rew_mean          | 0.571        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 1152         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026178067 |\n",
      "|    clip_fraction        | 0.209        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.0444       |\n",
      "|    learning_rate        | 0.00024      |\n",
      "|    loss                 | 0.349        |\n",
      "|    n_updates            | 32           |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    value_loss           | 1.23         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.9         |\n",
      "|    ep_rew_mean          | 0.8          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 1280         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011965609 |\n",
      "|    clip_fraction        | 0.168        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0.114        |\n",
      "|    learning_rate        | 0.000238     |\n",
      "|    loss                 | 2.57         |\n",
      "|    n_updates            | 36           |\n",
      "|    policy_gradient_loss | -0.000404    |\n",
      "|    value_loss           | 0.725        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 82.2         |\n",
      "|    ep_rew_mean          | 0.941        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 1408         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032776021 |\n",
      "|    clip_fraction        | 0.0898       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.99        |\n",
      "|    explained_variance   | 0.11         |\n",
      "|    learning_rate        | 0.000237     |\n",
      "|    loss                 | -0.00381     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.000512    |\n",
      "|    value_loss           | 0.495        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 82          |\n",
      "|    ep_rew_mean          | 1.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 1536        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004289657 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.999      |\n",
      "|    explained_variance   | 0.0993      |\n",
      "|    learning_rate        | 0.000236    |\n",
      "|    loss                 | 0.23        |\n",
      "|    n_updates            | 44          |\n",
      "|    policy_gradient_loss | -0.00161    |\n",
      "|    value_loss           | 0.893       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 81.8        |\n",
      "|    ep_rew_mean          | 0.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 1664        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004690974 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.978      |\n",
      "|    explained_variance   | 0.0369      |\n",
      "|    learning_rate        | 0.000235    |\n",
      "|    loss                 | 0.17        |\n",
      "|    n_updates            | 48          |\n",
      "|    policy_gradient_loss | -0.00402    |\n",
      "|    value_loss           | 0.398       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 80.9         |\n",
      "|    ep_rew_mean          | 0.977        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 1792         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030791229 |\n",
      "|    clip_fraction        | 0.254        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0.172        |\n",
      "|    learning_rate        | 0.000233     |\n",
      "|    loss                 | 0.293        |\n",
      "|    n_updates            | 52           |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    value_loss           | 0.711        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 82.1        |\n",
      "|    ep_rew_mean          | 0.913       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 1920        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005932035 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.000232    |\n",
      "|    loss                 | 0.46        |\n",
      "|    n_updates            | 56          |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    value_loss           | 0.665       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 82.1         |\n",
      "|    ep_rew_mean          | 1.02         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074691307 |\n",
      "|    clip_fraction        | 0.27         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.965       |\n",
      "|    explained_variance   | 0.237        |\n",
      "|    learning_rate        | 0.000231     |\n",
      "|    loss                 | 0.277        |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    value_loss           | 0.495        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 83.2        |\n",
      "|    ep_rew_mean          | 0.98        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 2176        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004438569 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.962      |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00023     |\n",
      "|    loss                 | 0.0988      |\n",
      "|    n_updates            | 64          |\n",
      "|    policy_gradient_loss | 0.00337     |\n",
      "|    value_loss           | 0.458       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 83.5         |\n",
      "|    ep_rew_mean          | 1.26         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 2304         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031778975 |\n",
      "|    clip_fraction        | 0.082        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.951       |\n",
      "|    explained_variance   | 0.129        |\n",
      "|    learning_rate        | 0.000228     |\n",
      "|    loss                 | 0.059        |\n",
      "|    n_updates            | 68           |\n",
      "|    policy_gradient_loss | 0.00292      |\n",
      "|    value_loss           | 0.679        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 83.4        |\n",
      "|    ep_rew_mean          | 1.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 2432        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003416718 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.9        |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.000227    |\n",
      "|    loss                 | 0.4         |\n",
      "|    n_updates            | 72          |\n",
      "|    policy_gradient_loss | -0.00152    |\n",
      "|    value_loss           | 0.355       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 82.3        |\n",
      "|    ep_rew_mean          | 1.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 2560        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002579661 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.926      |\n",
      "|    explained_variance   | -0.0982     |\n",
      "|    learning_rate        | 0.000226    |\n",
      "|    loss                 | 0.131       |\n",
      "|    n_updates            | 76          |\n",
      "|    policy_gradient_loss | -0.00158    |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 81.4         |\n",
      "|    ep_rew_mean          | 1.2          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 102          |\n",
      "|    total_timesteps      | 2688         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023642695 |\n",
      "|    clip_fraction        | 0.234        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.891       |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.000224     |\n",
      "|    loss                 | 0.0121       |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000332    |\n",
      "|    value_loss           | 0.156        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 81.9        |\n",
      "|    ep_rew_mean          | 1.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 2816        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007094173 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.896      |\n",
      "|    explained_variance   | -0.71       |\n",
      "|    learning_rate        | 0.000223    |\n",
      "|    loss                 | 0.0502      |\n",
      "|    n_updates            | 84          |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 81.1        |\n",
      "|    ep_rew_mean          | 1.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 2944        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002710817 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.875      |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.000222    |\n",
      "|    loss                 | 0.182       |\n",
      "|    n_updates            | 88          |\n",
      "|    policy_gradient_loss | 0.00585     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 82.5        |\n",
      "|    ep_rew_mean          | 1.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003476045 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.988      |\n",
      "|    explained_variance   | -0.778      |\n",
      "|    learning_rate        | 0.000221    |\n",
      "|    loss                 | 0.0149      |\n",
      "|    n_updates            | 92          |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    value_loss           | 0.247       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 82.3        |\n",
      "|    ep_rew_mean          | 1.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 3200        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007876877 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.95       |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.000219    |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 96          |\n",
      "|    policy_gradient_loss | 0.000548    |\n",
      "|    value_loss           | 0.687       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 82.5        |\n",
      "|    ep_rew_mean          | 1.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 3328        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004376423 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.000218    |\n",
      "|    loss                 | 0.0672      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00141    |\n",
      "|    value_loss           | 0.258       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 82.2         |\n",
      "|    ep_rew_mean          | 1.2          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 3456         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052434905 |\n",
      "|    clip_fraction        | 0.23         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.336        |\n",
      "|    learning_rate        | 0.000217     |\n",
      "|    loss                 | -0.00321     |\n",
      "|    n_updates            | 104          |\n",
      "|    policy_gradient_loss | -0.0125      |\n",
      "|    value_loss           | 0.305        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 83.2         |\n",
      "|    ep_rew_mean          | 1.15         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 3584         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049196547 |\n",
      "|    clip_fraction        | 0.295        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.000215     |\n",
      "|    loss                 | 0.104        |\n",
      "|    n_updates            | 108          |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    value_loss           | 0.321        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 83.9         |\n",
      "|    ep_rew_mean          | 1.24         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 141          |\n",
      "|    total_timesteps      | 3712         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056873616 |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.422        |\n",
      "|    learning_rate        | 0.000214     |\n",
      "|    loss                 | -0.0163      |\n",
      "|    n_updates            | 112          |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    value_loss           | 0.383        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 85.2        |\n",
      "|    ep_rew_mean          | 1.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 3840        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036412474 |\n",
      "|    clip_fraction        | 0.479       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.000213    |\n",
      "|    loss                 | 0.149       |\n",
      "|    n_updates            | 116         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 85.3       |\n",
      "|    ep_rew_mean          | 1.34       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 26         |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 151        |\n",
      "|    total_timesteps      | 3968       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00429849 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.99      |\n",
      "|    explained_variance   | 0.534      |\n",
      "|    learning_rate        | 0.000212   |\n",
      "|    loss                 | 0.752      |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | 0.00191    |\n",
      "|    value_loss           | 0.328      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 85.9         |\n",
      "|    ep_rew_mean          | 1.3          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 156          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029131523 |\n",
      "|    clip_fraction        | 0.225        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.946       |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.00021      |\n",
      "|    loss                 | 0.0428       |\n",
      "|    n_updates            | 124          |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    value_loss           | 0.161        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 86          |\n",
      "|    ep_rew_mean          | 1.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 4224        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006654641 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.000209    |\n",
      "|    loss                 | 0.0102      |\n",
      "|    n_updates            | 128         |\n",
      "|    policy_gradient_loss | -0.00717    |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 86.2         |\n",
      "|    ep_rew_mean          | 1.39         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 166          |\n",
      "|    total_timesteps      | 4352         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047544176 |\n",
      "|    clip_fraction        | 0.262        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.966       |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.000208     |\n",
      "|    loss                 | 0.00181      |\n",
      "|    n_updates            | 132          |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    value_loss           | 0.253        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 86.7         |\n",
      "|    ep_rew_mean          | 1.41         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 4480         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104564065 |\n",
      "|    clip_fraction        | 0.326        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.912       |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.000206     |\n",
      "|    loss                 | -0.0821      |\n",
      "|    n_updates            | 136          |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    value_loss           | 0.21         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 86.3        |\n",
      "|    ep_rew_mean          | 1.47        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 4608        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005086185 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.94       |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.000205    |\n",
      "|    loss                 | -0.00536    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 86.2         |\n",
      "|    ep_rew_mean          | 1.44         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 180          |\n",
      "|    total_timesteps      | 4736         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073437826 |\n",
      "|    clip_fraction        | 0.316        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.932       |\n",
      "|    explained_variance   | 0.35         |\n",
      "|    learning_rate        | 0.000204     |\n",
      "|    loss                 | 0.0853       |\n",
      "|    n_updates            | 144          |\n",
      "|    policy_gradient_loss | 0.0167       |\n",
      "|    value_loss           | 0.509        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 87.1         |\n",
      "|    ep_rew_mean          | 1.44         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 185          |\n",
      "|    total_timesteps      | 4864         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052983076 |\n",
      "|    clip_fraction        | 0.195        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.934       |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.000203     |\n",
      "|    loss                 | 0.272        |\n",
      "|    n_updates            | 148          |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    value_loss           | 0.25         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 87.3         |\n",
      "|    ep_rew_mean          | 1.52         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 191          |\n",
      "|    total_timesteps      | 4992         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063494337 |\n",
      "|    clip_fraction        | 0.215        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.967       |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.000201     |\n",
      "|    loss                 | -0.0299      |\n",
      "|    n_updates            | 152          |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 0.197        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 87.7         |\n",
      "|    ep_rew_mean          | 1.5          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 196          |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056163664 |\n",
      "|    clip_fraction        | 0.252        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.949       |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.0002       |\n",
      "|    loss                 | 0.024        |\n",
      "|    n_updates            | 156          |\n",
      "|    policy_gradient_loss | -0.00479     |\n",
      "|    value_loss           | 0.202        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 88.2         |\n",
      "|    ep_rew_mean          | 1.54         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 201          |\n",
      "|    total_timesteps      | 5248         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047657057 |\n",
      "|    clip_fraction        | 0.26         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.95        |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.000199     |\n",
      "|    loss                 | 0.0288       |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | 0.00641      |\n",
      "|    value_loss           | 0.212        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 88.3         |\n",
      "|    ep_rew_mean          | 1.58         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 206          |\n",
      "|    total_timesteps      | 5376         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088759065 |\n",
      "|    clip_fraction        | 0.246        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.941       |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.000198     |\n",
      "|    loss                 | -0.0902      |\n",
      "|    n_updates            | 164          |\n",
      "|    policy_gradient_loss | -0.00759     |\n",
      "|    value_loss           | 0.131        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 88.5         |\n",
      "|    ep_rew_mean          | 1.61         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 210          |\n",
      "|    total_timesteps      | 5504         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066179526 |\n",
      "|    clip_fraction        | 0.295        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.947       |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.000196     |\n",
      "|    loss                 | -0.0498      |\n",
      "|    n_updates            | 168          |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    value_loss           | 0.157        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 88.8        |\n",
      "|    ep_rew_mean          | 1.61        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 5632        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010358039 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.888      |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.000195    |\n",
      "|    loss                 | -0.0128     |\n",
      "|    n_updates            | 172         |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    value_loss           | 0.153       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 89.1         |\n",
      "|    ep_rew_mean          | 1.65         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 220          |\n",
      "|    total_timesteps      | 5760         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045876037 |\n",
      "|    clip_fraction        | 0.189        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.949       |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.000194     |\n",
      "|    loss                 | -0.011       |\n",
      "|    n_updates            | 176          |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    value_loss           | 0.0786       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 89          |\n",
      "|    ep_rew_mean          | 1.65        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 5888        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004617677 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.881      |\n",
      "|    explained_variance   | 0.0675      |\n",
      "|    learning_rate        | 0.000192    |\n",
      "|    loss                 | 0.17        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 89.8        |\n",
      "|    ep_rew_mean          | 1.68        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 6016        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007212928 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.931      |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.000191    |\n",
      "|    loss                 | 0.0275      |\n",
      "|    n_updates            | 184         |\n",
      "|    policy_gradient_loss | -0.00171    |\n",
      "|    value_loss           | 0.0706      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 89.9        |\n",
      "|    ep_rew_mean          | 1.76        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 235         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006387486 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.9        |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 0.00019     |\n",
      "|    loss                 | 0.0201      |\n",
      "|    n_updates            | 188         |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 89.9        |\n",
      "|    ep_rew_mean          | 1.76        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 6272        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008105887 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.783      |\n",
      "|    explained_variance   | -0.0353     |\n",
      "|    learning_rate        | 0.000189    |\n",
      "|    loss                 | -0.00525    |\n",
      "|    n_updates            | 192         |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 91.7        |\n",
      "|    ep_rew_mean          | 1.78        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 6400        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015550748 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.773      |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.000187    |\n",
      "|    loss                 | 0.296       |\n",
      "|    n_updates            | 196         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 91.9        |\n",
      "|    ep_rew_mean          | 1.85        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 6528        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004724096 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.784      |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.000186    |\n",
      "|    loss                 | -0.0349     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    value_loss           | 0.347       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 92.2       |\n",
      "|    ep_rew_mean          | 1.85       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 26         |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 255        |\n",
      "|    total_timesteps      | 6656       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02248501 |\n",
      "|    clip_fraction        | 0.275      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.739     |\n",
      "|    explained_variance   | 0.488      |\n",
      "|    learning_rate        | 0.000185   |\n",
      "|    loss                 | -0.0349    |\n",
      "|    n_updates            | 204        |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    value_loss           | 0.129      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 92.8        |\n",
      "|    ep_rew_mean          | 1.92        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 6784        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014090691 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.000183    |\n",
      "|    loss                 | 0.0382      |\n",
      "|    n_updates            | 208         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.0829      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 93           |\n",
      "|    ep_rew_mean          | 1.96         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 265          |\n",
      "|    total_timesteps      | 6912         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076265885 |\n",
      "|    clip_fraction        | 0.203        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.773       |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.000182     |\n",
      "|    loss                 | 0.251        |\n",
      "|    n_updates            | 212          |\n",
      "|    policy_gradient_loss | -0.0064      |\n",
      "|    value_loss           | 0.162        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 92.5        |\n",
      "|    ep_rew_mean          | 1.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 7040        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012002056 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.758      |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.000181    |\n",
      "|    loss                 | 0.216       |\n",
      "|    n_updates            | 216         |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    value_loss           | 0.0479      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 92.5        |\n",
      "|    ep_rew_mean          | 1.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009652134 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.778      |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00018     |\n",
      "|    loss                 | -0.0148     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 92.6        |\n",
      "|    ep_rew_mean          | 1.94        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 281         |\n",
      "|    total_timesteps      | 7296        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008598377 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.728      |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.000178    |\n",
      "|    loss                 | -0.0446     |\n",
      "|    n_updates            | 224         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 0.0836      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 92.9       |\n",
      "|    ep_rew_mean          | 1.96       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 25         |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 286        |\n",
      "|    total_timesteps      | 7424       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02824653 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.826     |\n",
      "|    explained_variance   | 0.539      |\n",
      "|    learning_rate        | 0.000177   |\n",
      "|    loss                 | -0.0208    |\n",
      "|    n_updates            | 228        |\n",
      "|    policy_gradient_loss | -0.0107    |\n",
      "|    value_loss           | 0.144      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 94.1        |\n",
      "|    ep_rew_mean          | 1.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 7552        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018896617 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.684      |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.000176    |\n",
      "|    loss                 | 0.0663      |\n",
      "|    n_updates            | 232         |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 94.4       |\n",
      "|    ep_rew_mean          | 2.06       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 25         |\n",
      "|    iterations           | 60         |\n",
      "|    time_elapsed         | 296        |\n",
      "|    total_timesteps      | 7680       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00782142 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.846     |\n",
      "|    explained_variance   | 0.529      |\n",
      "|    learning_rate        | 0.000174   |\n",
      "|    loss                 | 0.0682     |\n",
      "|    n_updates            | 236        |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    value_loss           | 0.625      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 94.8        |\n",
      "|    ep_rew_mean          | 2.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 301         |\n",
      "|    total_timesteps      | 7808        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008606296 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.795      |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.000173    |\n",
      "|    loss                 | -0.00855    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 2.12         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 25           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 306          |\n",
      "|    total_timesteps      | 7936         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067229825 |\n",
      "|    clip_fraction        | 0.291        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.762       |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.000172     |\n",
      "|    loss                 | 0.0381       |\n",
      "|    n_updates            | 244          |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    value_loss           | 0.0918       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 2.13         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 25           |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 312          |\n",
      "|    total_timesteps      | 8064         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031243903 |\n",
      "|    clip_fraction        | 0.188        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.62        |\n",
      "|    explained_variance   | 0.38         |\n",
      "|    learning_rate        | 0.000171     |\n",
      "|    loss                 | 0.0724       |\n",
      "|    n_updates            | 248          |\n",
      "|    policy_gradient_loss | -0.00865     |\n",
      "|    value_loss           | 0.0719       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.6        |\n",
      "|    ep_rew_mean          | 2.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 317         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015976634 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.702      |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.000169    |\n",
      "|    loss                 | -0.0636     |\n",
      "|    n_updates            | 252         |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    value_loss           | 0.0967      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.3        |\n",
      "|    ep_rew_mean          | 2.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 8320        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019138217 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.799      |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.000168    |\n",
      "|    loss                 | 0.0419      |\n",
      "|    n_updates            | 256         |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    value_loss           | 0.224       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.6        |\n",
      "|    ep_rew_mean          | 2.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 326         |\n",
      "|    total_timesteps      | 8448        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008693125 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.735      |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.000167    |\n",
      "|    loss                 | -0.0415     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.0631      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.8        |\n",
      "|    ep_rew_mean          | 2.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 331         |\n",
      "|    total_timesteps      | 8576        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013925707 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.773      |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.000166    |\n",
      "|    loss                 | 0.00313     |\n",
      "|    n_updates            | 264         |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.9        |\n",
      "|    ep_rew_mean          | 2.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 337         |\n",
      "|    total_timesteps      | 8704        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015959684 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.725      |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.000164    |\n",
      "|    loss                 | 0.0714      |\n",
      "|    n_updates            | 268         |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.6        |\n",
      "|    ep_rew_mean          | 2.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 342         |\n",
      "|    total_timesteps      | 8832        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008707961 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.703      |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.000163    |\n",
      "|    loss                 | -0.0251     |\n",
      "|    n_updates            | 272         |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 96.3         |\n",
      "|    ep_rew_mean          | 2.2          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 25           |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 347          |\n",
      "|    total_timesteps      | 8960         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071269483 |\n",
      "|    clip_fraction        | 0.254        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.732       |\n",
      "|    explained_variance   | -0.101       |\n",
      "|    learning_rate        | 0.000162     |\n",
      "|    loss                 | 0.163        |\n",
      "|    n_updates            | 276          |\n",
      "|    policy_gradient_loss | -0.000129    |\n",
      "|    value_loss           | 0.255        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 96.6        |\n",
      "|    ep_rew_mean          | 2.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 9088        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008646503 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.824      |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00016     |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00128    |\n",
      "|    value_loss           | 0.583       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 96.5       |\n",
      "|    ep_rew_mean          | 2.34       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 25         |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 357        |\n",
      "|    total_timesteps      | 9216       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01203676 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.802     |\n",
      "|    explained_variance   | 0.613      |\n",
      "|    learning_rate        | 0.000159   |\n",
      "|    loss                 | -0.0465    |\n",
      "|    n_updates            | 284        |\n",
      "|    policy_gradient_loss | -0.00702   |\n",
      "|    value_loss           | 0.229      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 97.2        |\n",
      "|    ep_rew_mean          | 2.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 363         |\n",
      "|    total_timesteps      | 9344        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011891643 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.711      |\n",
      "|    explained_variance   | -0.829      |\n",
      "|    learning_rate        | 0.000158    |\n",
      "|    loss                 | 0.576       |\n",
      "|    n_updates            | 288         |\n",
      "|    policy_gradient_loss | 0.00823     |\n",
      "|    value_loss           | 0.341       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 97.2        |\n",
      "|    ep_rew_mean          | 2.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 368         |\n",
      "|    total_timesteps      | 9472        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010703746 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.691      |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.000157    |\n",
      "|    loss                 | 0.00646     |\n",
      "|    n_updates            | 292         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.606       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 98.3       |\n",
      "|    ep_rew_mean          | 2.43       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 25         |\n",
      "|    iterations           | 75         |\n",
      "|    time_elapsed         | 373        |\n",
      "|    total_timesteps      | 9600       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01178232 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.631     |\n",
      "|    explained_variance   | 0.33       |\n",
      "|    learning_rate        | 0.000155   |\n",
      "|    loss                 | 0.0323     |\n",
      "|    n_updates            | 296        |\n",
      "|    policy_gradient_loss | -0.00266   |\n",
      "|    value_loss           | 0.0658     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 98.5        |\n",
      "|    ep_rew_mean          | 2.46        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 378         |\n",
      "|    total_timesteps      | 9728        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013588182 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.755      |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.000154    |\n",
      "|    loss                 | -0.0524     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 98.5        |\n",
      "|    ep_rew_mean          | 2.46        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 9856        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013020277 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.744      |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.000153    |\n",
      "|    loss                 | -0.02       |\n",
      "|    n_updates            | 304         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 2.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 388         |\n",
      "|    total_timesteps      | 9984        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015761921 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.661      |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.000151    |\n",
      "|    loss                 | 0.0757      |\n",
      "|    n_updates            | 308         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 101         |\n",
      "|    ep_rew_mean          | 2.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 393         |\n",
      "|    total_timesteps      | 10112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017364247 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.82       |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.00015     |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 312         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    value_loss           | 0.363       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 101         |\n",
      "|    ep_rew_mean          | 2.71        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 398         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016512223 |\n",
      "|    clip_fraction        | 0.434       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.746      |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.000149    |\n",
      "|    loss                 | -0.0334     |\n",
      "|    n_updates            | 316         |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 101         |\n",
      "|    ep_rew_mean          | 2.71        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 404         |\n",
      "|    total_timesteps      | 10368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012960803 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.672      |\n",
      "|    explained_variance   | 0.826       |\n",
      "|    learning_rate        | 0.000148    |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 103         |\n",
      "|    ep_rew_mean          | 2.81        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 408         |\n",
      "|    total_timesteps      | 10496       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013117884 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.623      |\n",
      "|    explained_variance   | 0.0735      |\n",
      "|    learning_rate        | 0.000146    |\n",
      "|    loss                 | 0.0421      |\n",
      "|    n_updates            | 324         |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 103         |\n",
      "|    ep_rew_mean          | 2.81        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 413         |\n",
      "|    total_timesteps      | 10624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021689944 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.609      |\n",
      "|    explained_variance   | 0.81        |\n",
      "|    learning_rate        | 0.000145    |\n",
      "|    loss                 | -0.0233     |\n",
      "|    n_updates            | 328         |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    value_loss           | 0.227       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 104        |\n",
      "|    ep_rew_mean          | 2.94       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 25         |\n",
      "|    iterations           | 84         |\n",
      "|    time_elapsed         | 418        |\n",
      "|    total_timesteps      | 10752      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02220187 |\n",
      "|    clip_fraction        | 0.34       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.545     |\n",
      "|    explained_variance   | 0.0258     |\n",
      "|    learning_rate        | 0.000144   |\n",
      "|    loss                 | -0.0098    |\n",
      "|    n_updates            | 332        |\n",
      "|    policy_gradient_loss | -0.0191    |\n",
      "|    value_loss           | 0.132      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 106         |\n",
      "|    ep_rew_mean          | 2.98        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 424         |\n",
      "|    total_timesteps      | 10880       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010962896 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.596      |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.000142    |\n",
      "|    loss                 | -0.0319     |\n",
      "|    n_updates            | 336         |\n",
      "|    policy_gradient_loss | -0.00846    |\n",
      "|    value_loss           | 0.0856      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 106         |\n",
      "|    ep_rew_mean          | 3.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 429         |\n",
      "|    total_timesteps      | 11008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035114616 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.704      |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.000141    |\n",
      "|    loss                 | 0.0265      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    value_loss           | 0.277       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 106         |\n",
      "|    ep_rew_mean          | 3.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 434         |\n",
      "|    total_timesteps      | 11136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013024843 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.722      |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.00014     |\n",
      "|    loss                 | 0.0679      |\n",
      "|    n_updates            | 344         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 0.264       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 107         |\n",
      "|    ep_rew_mean          | 3.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 439         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017687801 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.744      |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.000139    |\n",
      "|    loss                 | 0.0418      |\n",
      "|    n_updates            | 348         |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 108         |\n",
      "|    ep_rew_mean          | 3.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 444         |\n",
      "|    total_timesteps      | 11392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022740334 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.778      |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.000137    |\n",
      "|    loss                 | -0.0204     |\n",
      "|    n_updates            | 352         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 0.277       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 107         |\n",
      "|    ep_rew_mean          | 3.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 449         |\n",
      "|    total_timesteps      | 11520       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016553769 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.676      |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.000136    |\n",
      "|    loss                 | -0.0488     |\n",
      "|    n_updates            | 356         |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 107         |\n",
      "|    ep_rew_mean          | 3.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 454         |\n",
      "|    total_timesteps      | 11648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016670657 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.744      |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.000135    |\n",
      "|    loss                 | 0.057       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    value_loss           | 0.243       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 108         |\n",
      "|    ep_rew_mean          | 3.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 458         |\n",
      "|    total_timesteps      | 11776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020411903 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.746      |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.000134    |\n",
      "|    loss                 | -0.0454     |\n",
      "|    n_updates            | 364         |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 109         |\n",
      "|    ep_rew_mean          | 3.38        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 464         |\n",
      "|    total_timesteps      | 11904       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017046161 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.739      |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.000132    |\n",
      "|    loss                 | 0.0708      |\n",
      "|    n_updates            | 368         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 109         |\n",
      "|    ep_rew_mean          | 3.46        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 469         |\n",
      "|    total_timesteps      | 12032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019488236 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.716      |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.000131    |\n",
      "|    loss                 | -0.00183    |\n",
      "|    n_updates            | 372         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 110        |\n",
      "|    ep_rew_mean          | 3.44       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 25         |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 474        |\n",
      "|    total_timesteps      | 12160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01579276 |\n",
      "|    clip_fraction        | 0.342      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.642     |\n",
      "|    explained_variance   | 0.238      |\n",
      "|    learning_rate        | 0.00013    |\n",
      "|    loss                 | 0.0396     |\n",
      "|    n_updates            | 376        |\n",
      "|    policy_gradient_loss | -0.0136    |\n",
      "|    value_loss           | 0.12       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 110         |\n",
      "|    ep_rew_mean          | 3.5         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 479         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021944616 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.758      |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.000128    |\n",
      "|    loss                 | 0.0243      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 0.239       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 110         |\n",
      "|    ep_rew_mean          | 3.5         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 486         |\n",
      "|    total_timesteps      | 12416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022929944 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.711      |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.000127    |\n",
      "|    loss                 | -0.024      |\n",
      "|    n_updates            | 384         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.0999      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 111         |\n",
      "|    ep_rew_mean          | 3.54        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 491         |\n",
      "|    total_timesteps      | 12544       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034043163 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.728      |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.000126    |\n",
      "|    loss                 | 0.0717      |\n",
      "|    n_updates            | 388         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 112         |\n",
      "|    ep_rew_mean          | 3.62        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 496         |\n",
      "|    total_timesteps      | 12672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025321342 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.697      |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.000125    |\n",
      "|    loss                 | 0.0515      |\n",
      "|    n_updates            | 392         |\n",
      "|    policy_gradient_loss | 0.00477     |\n",
      "|    value_loss           | 0.583       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 112         |\n",
      "|    ep_rew_mean          | 3.71        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 501         |\n",
      "|    total_timesteps      | 12800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026344122 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.674      |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.000123    |\n",
      "|    loss                 | 0.0207      |\n",
      "|    n_updates            | 396         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 113         |\n",
      "|    ep_rew_mean          | 3.75        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 506         |\n",
      "|    total_timesteps      | 12928       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038078286 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.721      |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.000122    |\n",
      "|    loss                 | 0.0161      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 113         |\n",
      "|    ep_rew_mean          | 3.83        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 511         |\n",
      "|    total_timesteps      | 13056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029695313 |\n",
      "|    clip_fraction        | 0.391       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.761      |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.000121    |\n",
      "|    loss                 | -0.063      |\n",
      "|    n_updates            | 404         |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    value_loss           | 0.252       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 114         |\n",
      "|    ep_rew_mean          | 3.87        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 516         |\n",
      "|    total_timesteps      | 13184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034565616 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.702      |\n",
      "|    explained_variance   | 0.67        |\n",
      "|    learning_rate        | 0.000119    |\n",
      "|    loss                 | 0.0557      |\n",
      "|    n_updates            | 408         |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 114         |\n",
      "|    ep_rew_mean          | 3.87        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 521         |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014458935 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.703      |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.000118    |\n",
      "|    loss                 | 0.164       |\n",
      "|    n_updates            | 412         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 115        |\n",
      "|    ep_rew_mean          | 3.97       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 25         |\n",
      "|    iterations           | 105        |\n",
      "|    time_elapsed         | 527        |\n",
      "|    total_timesteps      | 13440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01809793 |\n",
      "|    clip_fraction        | 0.344      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.516     |\n",
      "|    explained_variance   | -1.02      |\n",
      "|    learning_rate        | 0.000117   |\n",
      "|    loss                 | 0.0359     |\n",
      "|    n_updates            | 416        |\n",
      "|    policy_gradient_loss | -0.0241    |\n",
      "|    value_loss           | 0.095      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTRAINING_TIMESTEPS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m agent.save(os.path.join(CHECKPOINT_DIR, log_name))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\StevenvdKamp\\.conda\\envs\\VizDoom\\Lib\\site-packages\\sb3_contrib\\ppo_recurrent\\ppo_recurrent.py:450\u001b[39m, in \u001b[36mRecurrentPPO.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlearn\u001b[39m(\n\u001b[32m    442\u001b[39m     \u001b[38;5;28mself\u001b[39m: SelfRecurrentPPO,\n\u001b[32m    443\u001b[39m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    448\u001b[39m     progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    449\u001b[39m ) -> SelfRecurrentPPO:\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\StevenvdKamp\\.conda\\envs\\VizDoom\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:335\u001b[39m, in \u001b[36mOnPolicyAlgorithm.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m log_interval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m iteration % log_interval == \u001b[32m0\u001b[39m:\n\u001b[32m    334\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ep_info_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdump_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28mself\u001b[39m.train()\n\u001b[32m    339\u001b[39m callback.on_training_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\StevenvdKamp\\.conda\\envs\\VizDoom\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:298\u001b[39m, in \u001b[36mOnPolicyAlgorithm.dump_logs\u001b[39m\u001b[34m(self, iteration)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.ep_success_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m    297\u001b[39m     \u001b[38;5;28mself\u001b[39m.logger.record(\u001b[33m\"\u001b[39m\u001b[33mrollout/success_rate\u001b[39m\u001b[33m\"\u001b[39m, safe_mean(\u001b[38;5;28mself\u001b[39m.ep_success_buffer))\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_timesteps\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\StevenvdKamp\\.conda\\envs\\VizDoom\\Lib\\site-packages\\stable_baselines3\\common\\logger.py:540\u001b[39m, in \u001b[36mLogger.dump\u001b[39m\u001b[34m(self, step)\u001b[39m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _format \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_formats:\n\u001b[32m    539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_format, KVWriter):\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m         \u001b[43m_format\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname_to_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname_to_excluded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[38;5;28mself\u001b[39m.name_to_value.clear()\n\u001b[32m    543\u001b[39m \u001b[38;5;28mself\u001b[39m.name_to_count.clear()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\StevenvdKamp\\.conda\\envs\\VizDoom\\Lib\\site-packages\\stable_baselines3\\common\\logger.py:437\u001b[39m, in \u001b[36mTensorBoardOutputFormat.write\u001b[39m\u001b[34m(self, key_values, key_excluded, step)\u001b[39m\n\u001b[32m    434\u001b[39m         \u001b[38;5;28mself\u001b[39m.writer.file_writer.add_summary(session_end_info)\n\u001b[32m    436\u001b[39m \u001b[38;5;66;03m# Flush the output to the file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\StevenvdKamp\\.conda\\envs\\VizDoom\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:1194\u001b[39m, in \u001b[36mSummaryWriter.flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1193\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m writer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.all_writers.values():\n\u001b[32m-> \u001b[39m\u001b[32m1194\u001b[39m     \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\StevenvdKamp\\.conda\\envs\\VizDoom\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:153\u001b[39m, in \u001b[36mFileWriter.flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mflush\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    148\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Flushes the event file to disk.\u001b[39;00m\n\u001b[32m    149\u001b[39m \n\u001b[32m    150\u001b[39m \u001b[33;03m    Call this method to make sure that all pending events have been written to\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[33;03m    disk.\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevent_writer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\StevenvdKamp\\.conda\\envs\\VizDoom\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:125\u001b[39m, in \u001b[36mEventFileWriter.flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mflush\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    120\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Flushes the event file to disk.\u001b[39;00m\n\u001b[32m    121\u001b[39m \n\u001b[32m    122\u001b[39m \u001b[33;03m    Call this method to make sure that all pending events have been\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[33;03m    written to disk.\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_async_writer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\StevenvdKamp\\.conda\\envs\\VizDoom\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:189\u001b[39m, in \u001b[36m_AsyncWriter.flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._closed:\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mWriter is closed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_byte_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[38;5;28mself\u001b[39m._writer.flush()\n\u001b[32m    191\u001b[39m \u001b[38;5;66;03m# Check the status again in case the background worker thread has\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# failed in the meantime to avoid waiting until the next call to\u001b[39;00m\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# surface the error.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\StevenvdKamp\\.conda\\envs\\VizDoom\\Lib\\queue.py:90\u001b[39m, in \u001b[36mQueue.join\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.all_tasks_done:\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unfinished_tasks:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mall_tasks_done\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\StevenvdKamp\\.conda\\envs\\VizDoom\\Lib\\threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "agent.learn(total_timesteps=TRAINING_TIMESTEPS, callback=callback, tb_log_name=log_name)\n",
    "agent.save(os.path.join(CHECKPOINT_DIR, log_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save(os.path.join(CHECKPOINT_DIR, log_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c55a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "envs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e21c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_HYPERPARAMS = {\n",
    "    \"policy\": \"CnnLstmPolicy\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "037a2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "def sampleRPPO_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
    "    \"\"\"Sampler for RPPO hyperparameters.\"\"\"\n",
    "    learning_rate = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 4, 12, log=True)\n",
    "    gamma = 1 - trial.suggest_float(\"gamma\", 0.0001, 0.1, log=True)\n",
    "    gae_lambda = 1 - trial.suggest_float(\"gae_lambda\", 0.001, 0.2, log=True)\n",
    "    clip_range = trial.suggest_float(\"clip_range\", 0.1, 0.3, log=True)\n",
    "    ent_coef = trial.suggest_float(\"ent_coef\", 0.00000001, 0.1, log=True)\n",
    "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True)\n",
    "\n",
    "    trial.set_user_attr(\"learning_rate\", learning_rate)\n",
    "    trial.set_user_attr(\"n_steps\", n_steps)\n",
    "    trial.set_user_attr(\"gamma\", gamma)\n",
    "    trial.set_user_attr(\"gae_lambda\", gae_lambda)\n",
    "    trial.set_user_attr(\"clip_range\", clip_range)\n",
    "    trial.set_user_attr(\"ent_coef\", ent_coef)\n",
    "    trial.set_user_attr(\"max_grad_norm\", max_grad_norm)\n",
    "\n",
    "    return {\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"n_steps\": n_steps,\n",
    "        \"gamma\": gamma,\n",
    "        \"gae_lambda\": gae_lambda,\n",
    "        \"clip_range\": clip_range,\n",
    "        \"ent_coef\": ent_coef,\n",
    "        \"max_grad_norm\": max_grad_norm,\n",
    "    }\n",
    "\n",
    "class TrailEvalCallback(sb3.common.callbacks.EvalCallback):\n",
    "    \"\"\"Callback for training and evaluation of the agent.\"\"\"\n",
    "\n",
    "    def __init__(self, eval_env, trail, n_eval_episodes = 5, eval_freq=10000, deterministic = True, verbose=0):\n",
    "        super().__init__(\n",
    "            eval_env=eval_env,\n",
    "            n_eval_episodes=n_eval_episodes,\n",
    "            eval_freq=eval_freq,\n",
    "            deterministic=deterministic,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        self.trail = trail\n",
    "        self.eval_idx = 0\n",
    "        self.is_pruned = False\n",
    "        \n",
    "    def _on_step(self) -> bool:\n",
    "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
    "            super()._on_step()\n",
    "            self.eval_idx += 1\n",
    "            self.trail.report(self.last_mean_reward, self.eval_idx)\n",
    "            if self.trail.should_prune():\n",
    "                self.is_pruned = True\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "def objective(trial:optuna.Trial) -> float:\n",
    "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
    "    kwargs.update(sampleRPPO_params(trial))\n",
    "    model = sb3_contrib.RecurrentPPO(**kwargs, env=VizDoomEnv(DEFAULT_SCENARIO_PATH, render=False))\n",
    "    eval_env = VizDoomEnv(DEFAULT_SCENARIO_PATH, render=True)\n",
    "    eval_callback = TrailEvalCallback(eval_env, trial, n_eval_episodes=5, eval_freq=10000, deterministic=True)\n",
    "    nan_encountered = False\n",
    "    try:\n",
    "        model.learn(total_timesteps=TRAINING_TIMESTEPS, callback=eval_callback, tb_log_name=\"RPPO_optuna\")\n",
    "    except AssertionError as e:\n",
    "        print(e)\n",
    "        nan_encountered = True\n",
    "    finally:\n",
    "        model.env.close()\n",
    "        eval_env.close()\n",
    "\n",
    "    if nan_encountered:\n",
    "        return float(\"nan\")\n",
    "    if eval_callback.is_pruned:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    return eval_callback.last_mean_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d042644c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-21 12:20:22,307] A new study created in memory with name: RPPO_optuna\n",
      "c:\\Users\\StevenvdKamp\\.conda\\envs\\VizDoom\\Lib\\site-packages\\stable_baselines3\\common\\callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x000001BF5C9D8750> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001BF31CA9BD0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "c:\\Users\\StevenvdKamp\\.conda\\envs\\VizDoom\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "[I 2025-07-21 12:37:58,231] Trial 0 finished with value: 0.0 and parameters: {'lr': 9.930864771263567e-05, 'exponent_n_steps': 9, 'gamma': 0.04025193382173653, 'gae_lambda': 0.0010456285636645574, 'clip_range': 0.11352758425153635, 'ent_coef': 0.023887135560622993, 'max_grad_norm': 4.367095939444027}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  1\n",
      "Best trial:\n",
      "  Value:  0.0\n",
      "  Params: \n",
      "    lr: 9.930864771263567e-05\n",
      "    exponent_n_steps: 9\n",
      "    gamma: 0.04025193382173653\n",
      "    gae_lambda: 0.0010456285636645574\n",
      "    clip_range: 0.11352758425153635\n",
      "    ent_coef: 0.023887135560622993\n",
      "    max_grad_norm: 4.367095939444027\n",
      "  User attrs:\n",
      "    learning_rate: 9.930864771263567e-05\n",
      "    n_steps: 512\n",
      "    gamma: 0.9597480661782635\n",
      "    gae_lambda: 0.9989543714363355\n",
      "    clip_range: 0.11352758425153635\n",
      "    ent_coef: 0.023887135560622993\n",
      "    max_grad_norm: 4.367095939444027\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(1)\n",
    "sampler = optuna.samplers.TPESampler(n_startup_trials=5)\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=1)\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=sampler,\n",
    "    pruner=pruner,\n",
    "    study_name=\"RPPO_optuna\",\n",
    ")\n",
    "try:\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "print(\"  User attrs:\")\n",
    "for key, value in trial.user_attrs.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6e77e6",
   "metadata": {},
   "source": [
    "Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4d272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload model from disc\n",
    "agent = sb3.PPO.load(r'.\\train\\train_center\\RPPO_blogAtariSettings_BW.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f79990",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VizDoomEnv(DEFAULT_SCENARIO_PATH, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c5c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward = sb3.common.evaluation.evaluate_policy(agent, env, n_eval_episodes=10, deterministic=True)\n",
    "env.close()\n",
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c436f846",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = VizDoomEnv(DEFAULT_SCENARIO_PATH, render=True)\n",
    "for episode in range(2): \n",
    "    obs = test_env.reset()[0]\n",
    "    done = False\n",
    "    state = None\n",
    "    episode_starts = True\n",
    "\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, state = agent.predict(obs, state=state, episode_start=episode_starts)\n",
    "        obs, reward, done, _, info = test_env.step(action)\n",
    "        episode_starts = done\n",
    "        time.sleep(0.1)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(total_reward, episode))\n",
    "    time.sleep(2)\n",
    "\n",
    "test_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dcf9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VizDoom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
